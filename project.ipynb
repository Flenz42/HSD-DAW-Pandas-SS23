{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T07:15:05.957968200Z",
     "start_time": "2023-05-30T07:15:05.027470800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipcalc\n",
    "import parse_functions as pf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import user_agents as ua\n",
    "#import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def filter_other(data, threshold_pct=0.03):\n",
    "    total = sum(data)\n",
    "    print(total)\n",
    "    threshold_abs = threshold_pct * total\n",
    "    filtered_data = data.loc[data >= threshold_abs]\n",
    "    excluded_data = data.loc[data < threshold_abs]\n",
    "    total_excluded = sum(excluded_data)\n",
    "    filtered_data['Other'] = total_excluded\n",
    "    return filtered_data\n",
    "\n",
    "def autopct_format(values):\n",
    "    def my_format(pct):\n",
    "        total = sum(values)\n",
    "        val = int(round(pct*total/100.0))\n",
    "        return '{:.1f}%\\n({v:d})'.format(pct, v=val)\n",
    "    return my_format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbereitung: Einlesen der Daten\n",
    "- Schwierigkeit: Größe des Datensatzes: 10.365.152 Daten (über 10 Milionen)\n",
    "- keine eindeutiges Trennzeichen in den Daten vorhanden\n",
    "- kein von Pandas vorgefertigter Import für Log Dateien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-30T07:15:05.394469100Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Source: https://mmas.github.io/read-apache-access-log-pandas\n",
    "access_log = pd.read_csv(\n",
    "    'data/access.log',\n",
    "    sep=r'\\s(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)(?![^\\[]*\\]\\s)',\n",
    "    engine='python',\n",
    "    na_values='-',\n",
    "    header=None,\n",
    "    usecols=[0, 3, 4, 5, 6, 7, 8],\n",
    "    names=['ip', 'time', 'request', 'status', 'size', 'referer', 'user_agent'],\n",
    "    converters={'time': pf.parse_datetime,\n",
    "                'request': pf.parse_str,\n",
    "                'status': int,\n",
    "                'size': int,\n",
    "                'referer': pf.parse_str,\n",
    "                'user_agent': pf.parse_str},\n",
    "    on_bad_lines='warn')\n",
    "\n",
    "access_log.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umwandlung in CSV Datei\n",
    "- Damit nicht jedes Mal Daten neu über das Log eingelesen werden müssen!\n",
    "- CSV Datei erstellen und für erneutes einlesen nutzbar (geht schneller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten in einer CSV Datei speichern\n",
    "filename = \"data/acces_log.csv\"\n",
    "access_log.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge eine Kopie der Daten als \"Backup\"\n",
    "access_log_backup = access_log.copy()\n",
    "len(access_log_backup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten aus CSV laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten aus CSV laden\n",
    "filename = \"data/acces_log.csv\"\n",
    "access_log_csv = pd.read_csv(filename)\n",
    "len(access_log_csv)\n",
    "access_log = access_log_csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten konvertieren & normalisieren\n",
    "Die in der CSV hinterlegten Daten in die benötigten Datentypen überführen\n",
    "\n",
    "- time: soll als Datum im Pandas Dataframe hinterlegt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typen konvertieren\n",
    "access_log[\"time\"] = pd.to_datetime(access_log[\"time\"])\n",
    "\n",
    "# Daten normalisieren\n",
    "access_log['time'] = access_log['time'].dt.tz_convert('UTC')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 1: Beliebtestes Produkt\n",
    "\n",
    "> Analysieren Sie welche Produkte beliebt sind. Entwickeln Sie dazu eine Definition eines beliebten Produktes. Stellen Sie die Ergebnisse anschaulich da.\n",
    "\n",
    "## Definition\n",
    "\n",
    "> **Unsere Definition:**  \n",
    "  Das Produkt mit dein meisten Aufrufen auf dem Webserver\n",
    "\n",
    "## Ergebnis\n",
    "\n",
    "Product: Galaxy-J6-Plus-Dual-32GB | ProductID 33968\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_viewed_products = access_log.loc[access_log['request'].str.contains(r'^GET /product/\\d+', na=False)].value_counts(access_log['request'])\n",
    "print(most_viewed_products[0], most_viewed_products.keys()[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2\n",
    "\n",
    "> Untersuchen Sie den Datensatz auf weitere Auffälligkeiten.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basisinformationen durch Panda Befehle\n",
    "- Pandas bietet bereits vordefinierte Befehle um einfache Informationen über die Daten zu ermitteln\n",
    "- Ein Start mit den Befehlen hilft dabei die Daten zu erkunden\n",
    "- Speziell bei numerrischen Daten erhält man bereits eine Reihe an spannenden statistischen Informationen, aber auch Daten wie eine solche Log Datei, lohnt es sich beide Befehle kurz anzugucken\n",
    "\n",
    "### Befehl `.info()`\n",
    "- Übersicht über die Spalten\n",
    "- Angabe zu den Datentypen der Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "access_log.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Befehl `.describe()`\n",
    "- Anzahl der Einträge\n",
    "- wie viele einzigartige Einträge\n",
    "- höchste Zahl\n",
    "- durchschnitt\n",
    "- einiges mehr\n",
    "\n",
    "--> Statistische Basisinformationen <br>\n",
    "--> Parameter `include = 'all'` notwendig, dass auch nicht numerische Daten aufgeführt werden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_log.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_log.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_log[10000:10200]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo: prüfen ob wir das drin haben wollen / raus nehmen möchten? -> wäre nur ne kleine Hilfestellung zum Zugriff auf Attribute\n",
    "## Grundlage Zugriff auf Attribute:\n",
    "\n",
    "- Aufruf möglich durch ``acces_log.ip`` oder ``auch acces_log[\"ip\"]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IP-Adressen mit den meisten Aufrufen \n",
    "access_log.value_counts(\"ip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenergänzung / Datenaufbereitung zur Analyse\n",
    "\n",
    "### Timestamps:\n",
    "- Zur Analyse des Timestamps werden einzelne Spalten für Tag, Stunde (ToDo: Minute? Uhrzeit allgemein) erstellt\n",
    "- Die neu erstellten Features können für Untersuchungen wir Aufrufe nach Tageszeit verwendet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "days = []\n",
    "weekday = []\n",
    "\n",
    "for timestamp in access_log[\"time\"]:\n",
    "    days.append(timestamp.date())\n",
    "    weekday.append(calendar.day_name[timestamp.weekday()])\n",
    "\n",
    "access_log[\"day\"] = days\n",
    "access_log[\"weekday\"] = weekday\n",
    "access_log[\"time_of_day\"] = access_log['time'].dt.time\n",
    "access_log[\"minute\"] = access_log['time'].dt.minute\n",
    "access_log['hour'] = access_log['time'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_log.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse der herausgearbeiteten Timestamp Eigenschaften \n",
    "- Analyse von Tag\n",
    "- Analyse von Stunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse der Tage (Zugriffstage)\n",
    "days_count = access_log.value_counts(\"day\")\n",
    "print(days_count)\n",
    "days_count.sort_index().plot(kind='bar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausertung Tagesanzahl\n",
    "- Die Log-Datei enthält Informationen zu 5 Tagen\n",
    "- Die ersten beiden Tage haben eine leicht höhere Anzahl an Anfragen, ansonsten aber eine relativ gleiche Verteilung der Last über alle Tage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse der Stunden (Zugriffszeiten)\n",
    "hours_count = access_log.value_counts(\"hour\")\n",
    "print(hours_count)\n",
    "hours_count.sort_index().plot(kind='bar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung Stundenanalyse (Zugriffszeiten)\n",
    "- Klares Tief in der Nacht zu erkennen\n",
    "- Morgens ab 5 Uhr steigt die Anzahl an Aufrufen rapide\n",
    "- Höch Peak ist um 8 Uhr Morgens\n",
    "- Über den Nachmittag zum Abend hin sinken die Aufrufe wieder deutlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: irgendwie verwerten? Time of the Day ist schön, aber bringt eigentlich nichts!\n",
    "access_log.value_counts(\"time_of_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: Entfernen, Minute bringt auch nichts (oder fällt uns was spanneds zur Verwendung noch ein?)\n",
    "access_log.value_counts(\"minute\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap Tageszeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wochentag und Tageszeit einlesen\n",
    "access_log['weekday'] = access_log['time'].dt.weekday\n",
    "access_log['daytime'] = access_log['time'].dt.hour\n",
    "\n",
    "daytime_access = access_log.groupby(['daytime']).size().to_frame(name = 'count').reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (5, 3))\n",
    "df_wide = daytime_access.pivot_table(columns='daytime', values='count', aggfunc=lambda x:x)\n",
    "heatmap = sns.heatmap(df_wide, linewidths=1.0,ax=ax)\n",
    "\n",
    "ax.set_xlim(0, 23)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "heatmap.set_title('Aufrufe nach Tageszeit')\n",
    "heatmap.set_xlabel('Uhrzeit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wochentag und Tageszeit einlesen\n",
    "access_log['weekday'] = access_log['time'].dt.weekday\n",
    "access_log['daytime'] = access_log['time'].dt.hour\n",
    "\n",
    "daytime_access = access_log.groupby(['weekday', 'daytime']).size().to_frame(name = 'count').reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (5, 3))\n",
    "df_wide = daytime_access.pivot_table(index='weekday',columns='daytime',values='count', aggfunc=lambda x:x)\n",
    "heatmap = sns.heatmap(df_wide, linewidths=1.0,ax=ax)\n",
    "\n",
    "ax.set_xlim(0, 23)\n",
    "ax.set_ylim(0, 6)\n",
    "# ax.set_yticks(range(0, 7), ['Mo', 'Di', 'Mi', 'Do', 'Fr', 'Sa', 'So'])\n",
    "\n",
    "heatmap.set_title('Aufrufe nach Tag/Uhrzeit')\n",
    "heatmap.set_xlabel('Uhrzeit')\n",
    "heatmap.set_ylabel('Wochentag')\n",
    "\n",
    "# 1 => Dienstag\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Methods\n",
    "\n",
    "Die folgenden Request Methoden gibt es:  \n",
    "`GET`, `HEAD`, `POST`, `PUT`, `DELETE`, `CONNECT`, `OPTIONS`, `TRACE` und `PATCH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_method(request):\n",
    "  m = re.match(r'^[A-Z]+', str(request))\n",
    "  if m:\n",
    "    return m.group()\n",
    "  return None\n",
    "\n",
    "access_log['method'] = access_log['request'].map(extract_method)\n",
    "access_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_counts = access_log.loc[access_log['method'] != None]['method'].value_counts()\n",
    "\n",
    "method_counts = filter_other(method_counts, 0.005)\n",
    "\n",
    "method_counts.plot(kind='pie', title='Request Methods', ylabel='Method', autopct=autopct_format(method_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_counts.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_log.loc[access_log['method'] == 'POST'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Agents, Browser & OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = access_log['user_agent'].map(lambda agent: ua.parse(str(agent)))\n",
    "access_log['browser_family'] = agents.map(lambda agent: agent.browser.family)\n",
    "access_log['os_family'] = agents.map(lambda agent: agent.os.family)\n",
    "access_log['device_family'] = agents.map(lambda agent: agent.device.family)\n",
    "access_log['device_brand'] = agents.map(lambda agent: agent.device.brand)\n",
    "access_log['device_model'] = agents.map(lambda agent: agent.device.model)\n",
    "access_log['is_mobile'] = agents.map(lambda agent: agent.is_mobile)\n",
    "access_log['is_pc'] = agents.map(lambda agent: agent.is_pc)\n",
    "access_log['is_bot'] = agents.map(lambda agent: agent.is_bot)\n",
    "\n",
    "access_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser_family_counts = access_log['browser_family'].value_counts()\n",
    "\n",
    "browser_family_counts = filter_other(browser_family_counts)\n",
    "\n",
    "browser_family_counts.plot(kind='pie', title='Browsers', ylabel='Browser', autopct=autopct_format(browser_family_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_family_counts = access_log['os_family'].value_counts()\n",
    "\n",
    "os_family_counts = filter_other(os_family_counts)\n",
    "\n",
    "os_family_counts.plot(kind='pie', title='OS', ylabel='OS', autopct=autopct_format(os_family_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_counts = access_log['is_bot'].value_counts()\n",
    "\n",
    "bot_counts.plot(kind='pie', title='Bots', ylabel='Bots', autopct=autopct_format(bot_counts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reevaluation von Aufgabe 1\n",
    "\n",
    "Ändert sich das Ergebnis, wenn wir Bots ausschließen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnis von vorher\n",
    "print('Ergebnis von vorher')\n",
    "print(most_viewed_products[0], most_viewed_products.keys()[0])\n",
    "\n",
    "print()\n",
    "\n",
    "# Neues Ergebnis\n",
    "print('Neues Ergebnis')\n",
    "most_viewed_products2 = access_log.loc[access_log['is_bot'] != True].loc[access_log['request'].str.contains(r'^GET /product/\\d+', na=False)].value_counts(access_log['request'])\n",
    "print(most_viewed_products2[0], most_viewed_products2.keys()[0])\n",
    "\n",
    "print()\n",
    "\n",
    "# Evaluate\n",
    "if most_viewed_products.keys()[0] == most_viewed_products2.keys()[0]:\n",
    "    print('Gleiches Ergebnis')\n",
    "else:\n",
    "    print('Ergebnis verändert')\n",
    "print('Differenz:', most_viewed_products[0] - most_viewed_products2[0], 'Bot-Aufrufe')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fehler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_counts = access_log['status'].value_counts()\n",
    "\n",
    "status_counts = filter_other(status_counts, 0.01)\n",
    "\n",
    "status_counts.plot(kind='pie', title='Status', ylabel='Status Code', autopct=autopct_format(status_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_counts = access_log['status'].map(lambda status: status >= 400).value_counts()\n",
    "\n",
    "error_counts.plot(kind='pie', title='Failed requests', ylabel='Error?', autopct=autopct_format(error_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_logs = access_log.loc[access_log['status'] >= 400]\n",
    "\n",
    "error_code_counts = error_logs['status'].value_counts()\n",
    "\n",
    "error_code_counts = filter_other(error_code_counts, 0.01)\n",
    "\n",
    "error_code_counts.plot(kind='pie', title='Error', ylabel='Error Code', autopct=autopct_format(error_code_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_logs = access_log.loc[access_log['status'] != 200]\n",
    "error_logs.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_ip4 = pd.read_csv('data/geo-city/GeoLite2-City-Blocks-IPv4.csv')\n",
    "city_ip4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv('data/geo-city/GeoLite2-City-Locations-de.csv')\n",
    "locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = access_log.copy()\n",
    "copy['ip_n'] = pf.ip_to_int(copy['ip'])\n",
    "copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(city_ip4['network'].map(lambda network: ipcalc.Network(network)))\n",
    "\n",
    "def get_network_borders(network):\n",
    "    ip_network = ipcalc.Network(network)\n",
    "    if len(ip_network) > 0:\n",
    "        return [int(ip_network[0]), int(ip_network[-1])]\n",
    "    return [0, 0]\n",
    "\n",
    "# print(get_network_borders('1.0.8.0/21'))\n",
    "\n",
    "# print(city_ip4['network'][0:5].map(lambda network: get_network_borders(network)))\n",
    "\n",
    "city_ip4['ip_range'] = city_ip4['network'].map(lambda network: ipcalc.Network(network))\n",
    "city_ip4['ip_first'] = city_ip4['ip_range'].map(lambda ip: int(ip[0])).astype('int32')\n",
    "city_ip4['ip_last'] = city_ip4['ip_range'].map(lambda ip: int(ip[-1])).astype('int32')\n",
    "\n",
    "# city_ip4['ip_first'] = pf.ip_to_int(city_ip4['network'].map(lambda network: ipcalc.Network(network)[0]))\n",
    "# city_ip4['ip_last'] = pf.ip_to_int(city_ip4['network'].map(lambda network: ipcalc.Network(network)[-1]))\n",
    "\n",
    "city_ip4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip = 16778240\n",
    "# filtered = city_ip4.loc[city_ip4['ip_first'].le(ip)].loc[city_ip4['ip_last'].ge(ip)]\n",
    "# # filtered = filtered.loc[filtered['ip_last'].ge(ip)]\n",
    "# filtered.head()\n",
    "\n",
    "# copy['ip_n'][0:5].map(lambda ip: city_ip4.loc[city_ip4['ip_first'].le(ip)].loc[city_ip4['ip_last'].ge(ip)]['network'])\n",
    "\n",
    "\n",
    "# pd.concat([\n",
    "#     copy.loc[i, :].reset_index(drop=True),\n",
    "#     city_ip4.loc[j, :].reset_index(drop=True)\n",
    "# ], axis=1).append(\n",
    "#     copy[~np.in1d(np.arange(len(copy)), np.unique(i))],\n",
    "#     ignore_index=True, sort=False\n",
    "# )\n",
    "\n",
    "# copy.conditional_join(city_ip4, ('ip_n', 'ip_first', '>='), ('ip_n', 'ip_last', '<='))\n",
    "\n",
    "ips = copy['ip_n'].unique()\n",
    "ip_map = pd.DataFrame(ips, columns=['ip_n'])\n",
    "ip_map.conditional_join(city_ip4, ('ip_n', 'ip_first', '>='), ('ip_n', 'ip_last', '<='))\n",
    "\n",
    "\n",
    "\n",
    "# copy['network'] = copy['ip_n'].map(lambda ip: city_ip4.loc[city_ip4['ip_first'].le(ip)].loc[city_ip4['ip_last'].ge(ip)]['network'])\n",
    "# copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ip = 16778240\n",
    "# filtered = city_ip4.loc[city_ip4['ip_first'].le(ip)].loc[city_ip4['ip_last'].ge(ip)]\n",
    "# # filtered = filtered.loc[filtered['ip_last'].ge(ip)]\n",
    "# filtered.head()\n",
    "\n",
    "# copy['ip_n'][0:5].map(lambda ip: city_ip4.loc[city_ip4['ip_first'].le(ip)].loc[city_ip4['ip_last'].ge(ip)]['network'])\n",
    "\n",
    "\n",
    "# pd.concat([\n",
    "#     copy.loc[i, :].reset_index(drop=True),\n",
    "#     city_ip4.loc[j, :].reset_index(drop=True)\n",
    "# ], axis=1).append(\n",
    "#     copy[~np.in1d(np.arange(len(copy)), np.unique(i))],\n",
    "#     ignore_index=True, sort=False\n",
    "# )\n",
    "\n",
    "# copy.conditional_join(city_ip4, ('ip_n', 'ip_first', '>='), ('ip_n', 'ip_last', '<='))\n",
    "\n",
    "ips = copy['ip_n'].unique()\n",
    "ip_map = pd.DataFrame(ips, columns=['ip_n'])\n",
    "ip_map.conditional_join(city_ip4, ('ip_n', 'ip_first', '>='), ('ip_n', 'ip_last', '<='))\n",
    "\n",
    "# def find_network(ip):\n",
    "#     m = city_ip4[(city_ip4['ip_first'] <= ip) & (city_ip4['ip_last'] >= ip)]\n",
    "#     if len(m) > 0:\n",
    "#         n = m.iloc[0]['network']\n",
    "#         return n\n",
    "#     return None\n",
    "\n",
    "# print(find_network(1400386853))\n",
    "\n",
    "\n",
    "# ip_map['network'] = ip_map['ip_n'][0:1000].map(find_network)\n",
    "\n",
    "ip_map.head()\n",
    "\n",
    "\n",
    "\n",
    "# copy['network'] = copy['ip_n'].map(lambda ip: city_ip4.loc[city_ip4['ip_first'].le(ip)].loc[city_ip4['ip_last'].ge(ip)]['network'])\n",
    "# copy.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Ideas\n",
    "\n",
    "- [x] Nutzung im Tagesverlauf (UTC) (Flo)\n",
    "  * Wochentage analysieren\n",
    "- [ ] IP auf Locations mappen\n",
    "- [ ] Nutzung nach Tageszeit (korrigiert nach Location / Timezone based on IP)\n",
    "- [x] Requests außer `GET`? (Flo)\n",
    "- [x] Aufrufe mit Status `!= 200` => Fehler\n",
    "- [ ] Referers analysieren\n",
    "- [ ] Nach Nutzer und Pfaden gruppieren und zählen => Entscheidungsfreudigkeit der Nutzer\n",
    "- [ ] Korrelation untersuchen\n",
    "- [ ] Sessions von Nutzern zählen / schätzen\n",
    "- [x] Browser analysieren (Flo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
